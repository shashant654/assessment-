# üöÄ Gemini API Integration - Testing & Validation Guide

## ‚úÖ What's Been Implemented

### **5 Key Requirements - All Complete:**

1. ‚úÖ **Real-Time Metrics (SSE)** - Dashboard displays live metrics updating every 2 seconds
2. ‚úÖ **Mobile Responsive Design** - Dashboard, conversation view, and all components responsive on mobile
3. ‚úÖ **Voice Input** - Web Speech API integrated with microphone button in conversation
4. ‚úÖ **Response Templates** - Full template system for quick responses
5. ‚úÖ **Gemini AI Integration** - Real AI conversations instead of mock responses

---

## üîß System Architecture

### Backend Services Running on Port 9000
```
‚úÖ Node.js Server
‚úÖ MongoDB Connection
‚úÖ Express API
‚úÖ WebSocket Support
‚úÖ Gemini API Client
‚úÖ SSE Metrics Streaming
```

### Frontend Services Running on Port 3001
```
‚úÖ React Application
‚úÖ Web Speech API (Voice Input)
‚úÖ SSE Metrics Subscription
‚úÖ Real-Time Conversation Updates
‚úÖ Responsive UI Components
```

### API Endpoints Enhanced
```
POST /api/llm/generate       ‚Üê Gemini API + Mock Fallback
POST /api/llm/sentiment      ‚Üê Gemini API + Mock Fallback
POST /api/llm/knowledge      ‚Üê Gemini API + Mock Fallback
GET  /api/analytics/stream   ‚Üê Real-time metrics (SSE)
```

---

## üìã Testing Checklist

### **Test 1: Dashboard Loads with Real-Time Metrics**
- [ ] Open http://localhost:3001
- [ ] Dashboard displays 4 metric cards (Total Conversations, Avg Response Time, Sentiment Score, Knowledge Base)
- [ ] Metrics update smoothly every 2 seconds
- [ ] Live indicator badge shows active metrics streaming

**Expected Screenshot:**
- Dashboard header with metrics cards
- Cards show numbers that change every 2 seconds
- Small green "Live" indicator visible

---

### **Test 2: Dashboard is Mobile Responsive**
- [ ] Open Developer Tools (F12)
- [ ] Click toggle device toolbar (mobile mode)
- [ ] Test at:
  - [ ] iPhone 12 (390√ó844)
  - [ ] iPad (768√ó1024)
  - [ ] Desktop (1920√ó1080)

**Expected Behavior:**
- **Mobile:** 1 metric per row, stacked vertically
- **Tablet:** 2 metrics per row
- **Desktop:** 4 metrics in one row
- Text sizes adjust appropriately
- Icons scale with screen size

---

### **Test 3: Voice Input Works**
- [ ] Click on a conversation from the list
- [ ] Look for microphone button in message input area
- [ ] Click microphone button
- [ ] Speak clearly: "What's my shipping status?"
- [ ] Click stop button
- [ ] Transcript appears in input field
- [ ] Click send button
- [ ] Message is sent with voice transcript

**Expected Behavior:**
- Microphone icon visible in input area
- Voice status shows: "Listening..." while recording
- Transcript displays exactly what was said
- Message sent successfully to AI

**Browsers that support Web Speech API:**
- ‚úÖ Chrome/Edge (recommended)
- ‚úÖ Safari
- ‚ö†Ô∏è Firefox (limited support)

---

### **Test 4: Real AI Conversations (Gemini API)**
- [ ] In conversation view, type: "I'd like to return my order"
- [ ] Click send
- [ ] Backend logs show: `‚úÖ Response generated using Gemini API`
- [ ] Response appears that addresses your return request
- [ ] Response is NOT a template (actual AI-generated)

**Examples of Gemini Responses:**
- "To return your order, please..." (specific, natural language)
- NOT: "To return that item, you'll need to {{instruction}}"

**Check Backend Logs:**
```
üì® Attempting to use Gemini API for response generation...
‚úÖ Response generated using Gemini API
```

---

### **Test 5: Voice + Gemini Integration**
- [ ] Use microphone to ask: "When will my order arrive?"
- [ ] Transcript appears in input field
- [ ] Click send
- [ ] Gemini API generates response about delivery time
- [ ] Response appears in conversation

**Expected:**
- Voice transcript: "When will my order arrive?"
- Gemini Response: "Based on your order, I can see..." (real AI response)

---

### **Test 6: Response Templates Still Work**
- [ ] In conversation, look for template button (if visible)
- [ ] Click on a template
- [ ] Template message appears in input
- [ ] Modify if needed and send
- [ ] Conversation continues with human + AI messages

---

### **Test 7: Sentiment Analysis (Real)**
- [ ] In conversation, type: "I'm absolutely thrilled with my purchase!"
- [ ] Message sent
- [ ] Check backend logs for sentiment analysis
- [ ] Sentiment should be detected as positive

**Expected Log:**
```
‚úÖ Sentiment analyzed using Gemini API
```

---

### **Test 8: Error Handling & Fallback**
- [ ] In `.env`, change `GEMINI_API_KEY` to invalid value
- [ ] Restart backend server
- [ ] Try to send a message in conversation
- [ ] System falls back to mock responses
- [ ] Backend logs show: `ü§ñ Using mock response generation`
- [ ] Conversation still works (with mock responses)

**This demonstrates:**
- Graceful degradation
- Fallback system works
- App doesn't crash on API errors

---

## üéØ Testing Scenarios by User Type

### **Customer Service Manager**
1. Open Dashboard
2. Monitor real-time metrics
3. See conversations updating in real-time via SSE
4. Verify voice input feature

### **Supervisor**
1. Click on specific conversation
2. View Gemini AI responses to customer messages
3. Use response templates to intervene if needed
4. See sentiment analysis of customer messages

### **Agent**
1. Handle customer conversations
2. Use voice input for hands-free operation
3. Reference knowledge base
4. Send templated or custom responses

---

## üìä Expected Behavior by Feature

### Real-Time Metrics (SSE)
```
Before Implementation: Stale data, manual refresh
After Implementation: Live updates every 2 seconds ‚úÖ
```

### Mobile Responsive
```
Before: Dashboard broken on mobile
After: Perfectly readable on all devices ‚úÖ
```

### Voice Input
```
Before: Manual typing only
After: Speak and type options available ‚úÖ
```

### Gemini AI
```
Before: Mock templated responses
After: Natural, contextual AI responses ‚úÖ
```

---

## üîç Debugging Commands

### **Check if Backend is Running**
```bash
curl http://localhost:9000/api/agents
# Expected: JSON response with agent list
```

### **Check Gemini API is Connected**
```bash
# Look in backend console for:
‚úÖ Gemini API initialized successfully
```

### **Check Frontend is Running**
```bash
curl http://localhost:3001
# Expected: HTML response
```

### **Check SSE Endpoint**
```bash
curl http://localhost:9000/api/analytics/stream?timeRange=today
# Expected: Stream of data events
```

---

## ‚öôÔ∏è Configuration Verification

### **.env File Check**
```bash
cat backend-starter/.env
# Should contain:
# PORT=9000
# MONGODB_URI=mongodb://localhost:27017/zangoh
# GEMINI_API_KEY=AIzaSyAZ1q3PX81IQKRQK2pd0v8qJEqUj1z4-jo
# NODE_ENV=development
```

### **Package Installation Check**
```bash
cd backend-starter
npm list @google/generative-ai
# Should show: @google/generative-ai@0.1.3
```

### **MongoDB Connection Check**
```bash
# Look in backend logs for:
Connected to MongoDB
```

---

## üö® Troubleshooting

### Issue: "Gemini API not responding"
**Solution:**
1. Verify `GEMINI_API_KEY` in `.env` is correct
2. Check internet connection
3. Check API key hasn't been revoked
4. Restart backend server

### Issue: "Voice input not working"
**Solution:**
1. Use Chrome or Edge (best support)
2. Check microphone permissions in browser
3. Verify `useSpeechRecognition.js` is loaded
4. Check browser console for errors (F12)

### Issue: "Metrics not updating"
**Solution:**
1. Check backend SSE endpoint: `GET /api/analytics/stream?timeRange=today`
2. Verify MongoDB is running
3. Check if metrics data exists in database
4. Run seed script: `node utils/seed.js`

### Issue: "Conversations not loading"
**Solution:**
1. Check backend is running: `curl http://localhost:9000/api/conversations`
2. Verify conversation ID in URL is valid
3. Run seed script: `node utils/seed.js`
4. Check MongoDB connection

---

## üìà Performance Expectations

| Metric | Expected | Actual |
|--------|----------|--------|
| Dashboard Load Time | < 2s | ? |
| First Message Response | < 5s | ? |
| Subsequent Messages | 1-3s | ? |
| Metrics Update Frequency | Every 2s | ? |
| Voice Input Latency | < 1s | ? |

---

## ‚ú® Success Criteria

### All Features Fully Implemented When:
- ‚úÖ Dashboard loads with live metrics updating every 2 seconds
- ‚úÖ All metrics are responsive on mobile (1 col) and desktop (4 col)
- ‚úÖ Voice input microphone button visible and functional
- ‚úÖ Real Gemini API responses appear (not mock templates)
- ‚úÖ Backend logs show "‚úÖ Response generated using Gemini API"
- ‚úÖ Conversations continue naturally with AI responses
- ‚úÖ Fallback to mock works if Gemini API unavailable
- ‚úÖ No console errors in browser (F12)
- ‚úÖ No server errors in backend logs

---

## üéâ Celebration Criteria

When ALL of these work:

```
‚úÖ Open Dashboard ‚Üí See live metrics updating
‚úÖ Go to mobile view ‚Üí See responsive layout
‚úÖ Click microphone ‚Üí Speak a message
‚úÖ Click send ‚Üí Get real Gemini AI response
‚úÖ Check backend logs ‚Üí See "‚úÖ Gemini API" message
‚úÖ Refresh page ‚Üí Metrics still streaming
‚úÖ Try multiple messages ‚Üí All get real responses
‚úÖ Disable internet ‚Üí System falls back to mock (gracefully)
```

**Then you have successfully implemented all 5 requirements!** üéâ

---

## üìû Quick Reference

**Ports:**
- Frontend: http://localhost:3001
- Backend: http://localhost:9000
- API Docs: http://localhost:9000/api-docs

**Key Files:**
- Backend Gemini: `backend-starter/geminiApi.js`
- Backend Routes: `backend-starter/mockLlmApi.js`
- Frontend Conversation: `frontend-starter/src/pages/ConversationView.js`
- Voice Hook: `frontend-starter/src/hooks/useSpeechRecognition.js`

**Restart Commands:**
```bash
# Backend
cd backend-starter && npm start

# Frontend
cd frontend-starter && npm start
```

---

**Last Updated:** January 2024  
**Status:** Ready for Full Testing ‚úÖ  
**All 5 Requirements:** IMPLEMENTED ‚úÖ
